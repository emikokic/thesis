{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se explorarán, en pequeños experimentos, distintas formas de representación de los datos del corpus WiNER (Ghaddar y Langlais 2017) para utilizarlos en la tarea de reconocimiento de entidades nombradas. Para esto se exploran distintas combinaciones de vectores de palabras como representación de una instancia de entrenamiento (Iacobacci et al. 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del Corpus WiNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documents.tar.bz2 : este archivo contiene 3239540 artículos de Wikipedia repartidos en 3223 archivos. Cantidad de oraciones: 54607542. Cada archivo contiene aproximadamente 1000 artículos nombrados por sus respectivos IDs. Los artículos están indexados por su wikiID seguidos de oraciones (una por línea), donde las palabras son remplazadas por sus ids.\n",
    "\n",
    "      ID <number>\n",
    "      1234 4522 23 4 4567\n",
    "      456 21 9890 123 7 0\n",
    "\n",
    "* document.vocab : este archivo contiene el mapeo de palabras (case sensitive); el formato es: \n",
    " \n",
    "      palabra #ocurrencias\n",
    "    \n",
    "  El ID de cada palabra es el número de línea en la cual ocurre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from corpus_WiNER.corpus_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ekokic/thesis_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "word_mapping = pd.read_csv('./corpus_WiNER/document.vocab', sep=' ', header=None, \n",
    "                           names=['word', 'frequency'], keep_default_na=False) \n",
    "                        # con esto evito que el parser trate como nan value a algunas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2021984, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>73411953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>68044881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>54241850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>40550466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>34602894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word frequency\n",
       "0  the  73411953\n",
       "1    ,  68044881\n",
       "2    .  54241850\n",
       "3   of  40550466\n",
       "4  and  34602894"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_mapping.shape)\n",
    "word_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021983"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_mapping['word'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los artículos del Documento \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = pd.read_csv('./corpus_WiNER/Documents/0', sep='ID', engine='python', header=None, names=['sentence', 'art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130209, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650 5590 753942 12 189 243 1 2039 47 257 682 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34 23207 1523 4 57193 15 10777 14353 4 157019 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "0                                                NaN  431388.0\n",
       "1  650 5590 753942 12 189 243 1 2039 47 257 682 1...       NaN\n",
       "2  34 23207 1523 4 57193 15 10777 14353 4 157019 ...       NaN\n",
       "3  418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...       NaN\n",
       "4  650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a asociarle a cada oración el ID del artículo al cual pertenece.\n",
    "\n",
    "Es importante recordar que el orden de las oraciones está dado por los índices del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_ID_list = doc_0['art_ID'].tolist()\n",
    "art_ID = 0\n",
    "for idx, elem in enumerate(art_ID_list):\n",
    "    if not np.isnan(elem):\n",
    "        art_ID = elem\n",
    "    else:\n",
    "        art_ID_list[idx] = art_ID\n",
    "doc_0['art_ID'] = art_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos ahora las filas con NaN que contenian los ID de los artículos inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = doc_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento contiene 128395 oraciones.\n",
      "El documento contiene 1814 artículos\n"
     ]
    }
   ],
   "source": [
    "print('El documento contiene {} oraciones.'.format(doc_0.shape[0]))\n",
    "print('El documento contiene {} artículos'.format(len(doc_0['art_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos que cada sentencia sea una lista de palabras codificadas y casteamos a int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0['sentence'] = doc_0['sentence'].map(lambda x: list(map(int, x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "1  [650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...  431388.0\n",
       "2  [34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...  431388.0\n",
       "3  [418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...  431388.0\n",
       "4  [650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...  431388.0\n",
       "5  [152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...  431388.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con un artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>[63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>[3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>[24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>[152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>[64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  art_ID\n",
       "2756  [63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...  1000.0\n",
       "2757  [3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...  1000.0\n",
       "2758  [24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...  1000.0\n",
       "2759  [152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...  1000.0\n",
       "2760  [64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...  1000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 1000]\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruimos la primera oración del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_decoder(sentence, word_mapping):\n",
    "    dec_sentence = []\n",
    "    for idx in sentence:\n",
    "        mapped_w = word_mapping.loc[idx, 'word']\n",
    "        dec_sentence.append(mapped_w)\n",
    "    return dec_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos article.columns.get_loc('sentence') para evitar hardcodear el índice correspondiente\n",
    "# a la columna 'sentence' que en este caso es 0\n",
    "sentence = article.iloc[0, article.columns.get_loc('sentence')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercule Poirot is a fictional Belgian detective , created by Agatha Christie .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "' '.join(dec_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings utilizando el modelo pre-entrenado word2vec de Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la librería Gensim https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos Google's pre-trained Word2Vec model.\n",
    "\n",
    "Utilizando KeyedVectors para cargar el modelo tiene la desventaja de que no se puede seguir entrenando. Pero es más eficiente que utilizar gensim.models.Word2Vec\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demora: 10.533671855926514\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# model = KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# model.save('./models/word2vecGoogle.model')\n",
    "w2v_model = KeyedVectors.load('../models/google/word2vecGoogle.model')\n",
    "end = time.time()\n",
    "print('demora: {}'.format(end-start))\n",
    "# model = Word2Vec.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de word embeddings: 3000000\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de word embeddings: {}'.format(len(w2v_model.vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidad de los vectores: 300\n"
     ]
    }
   ],
   "source": [
    "print('Dimensionalidad de los vectores: {}'.format(w2v_model.vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos distintas combinaciones de vectores de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación\n",
    "\n",
    "Este método consiste en concatenar los vectores de palabras que rodean una palabra objetivo en un vector más grande, que tiene un tamaño igual a las dimensiones agregadas de todos las proyecciones (embeddings) individuales.\n",
    "\n",
    "- $w_{ij}$ = peso asociado con la i-ésima dimensión del vector de la j-ésima palabra en la oración. NOTA: con los vectores de palabras de una oración se forma una matriz $w^{\\space D\\space x\\space L}$ donde $L$ es la cantidad de palabras de esa oración.\n",
    "- $D$ = dimensionalidad de los word vectors originales. Por ejemplo, al usar el modelo word2vec de Google se tiene $D$ = 300.\n",
    "- $W$ = tamaño de ventana que se define como el número de palabras en un solo lado.\n",
    "\n",
    "Nos interesa representar el contexto de la I-ésima palabra de la oración. \n",
    "\n",
    "La i-ésima dimensión del vector de concatenación, que tiene un tamaño de $2 W D$, se calcula de la siguiente manera:\n",
    "\n",
    "$$ e_{i} =\\begin{cases} \n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor < W \\\\\n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space 1\\space  +\\space\\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & c.c.\n",
    "   \\end{cases}$$\n",
    "   \n",
    "\n",
    "<br>\n",
    "Al tomar una ventana simétrica, se realiza un relleno (padding) con ceros a izquierda y/o derecha según corresponda para mantener la misma dimesionalidad en cada nuevo vector generado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promedio\n",
    "\n",
    "Como su nombre indica, se calcula el centroide de los embeddings de todas las palabras circundantes. La fórmula divide cada dimensión en $2W$ ya que el número de palabras del contexto es dos veces el tamaño de la ventana:\n",
    "\n",
    "$$e_{i} =\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} \\frac{w_{ij}}{2W}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento fraccional\n",
    "\n",
    "Una tercera estrategia para construir un vector de carácteristicas en base a los embeddings de palabras contextuales está inspirada en la forma en que Word2vec combina las palabras en el contexto. Aquí, se supone que la importancia de una palabra para nuestra representación es inversamente proporcional a su distancia respecto a la palabra objetivo.\n",
    "\n",
    "Por lo tanto, las palabras contextuales se ponderan en función de su distancia de la palabra objetivo:\n",
    "\n",
    "$$e_{i} =\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} *\\frac{W - \\lvert I-j\\rvert}{W}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento exponencial\n",
    "\n",
    "Funciona de manera similar al decaimiento fraccional, que le da más importancia al contexto cercano, pero en este caso la ponderación se realiza exponencialmente:\n",
    "\n",
    "$$e_{i} =\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} * (1 - \\alpha)^{\\lvert \\space I\\space-\\space j\\space\\rvert\\space-\\space1}$$\n",
    "\n",
    "donde $\\alpha = 1 - 0.1^{(W-1)^{-1}}$ es el parámetro de decaimiento. Elegimos el parámetro de tal manera que las palabras inmediatas que rodean a la palabra objetivo contribuyen 10 veces más que las últimas palabras en ambos lados de la ventana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos CoarseNE.tar.bz2\n",
    "\n",
    "Contiene menciones anotadas automáticamente con etiquetas de entidades nombradas (PER, LOC, ORG y MISC).\n",
    "\n",
    "El formato es:\n",
    "\n",
    "    ID artID\n",
    "    sentIdx begin end entityType\n",
    "    \n",
    "donde entityType[0] = PER | entityType[1] = LOC | entityType[2] = ORG | entityType[3] = MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarseNE_0 = pd.read_csv('./corpus_WiNER/CoarseNE/0', sep='ID', engine='python', header=None, names=['named-entity', 'art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259470, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>named-entity</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t0\\t2\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t5\\t6\\t1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t10\\t12\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\t2\\t4\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   named-entity  art_ID\n",
       "0           NaN  1000.0\n",
       "1    0\\t0\\t2\\t0     NaN\n",
       "2    0\\t5\\t6\\t1     NaN\n",
       "3  0\\t10\\t12\\t0     NaN\n",
       "4    1\\t2\\t4\\t0     NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(coarseNE_0.shape)\n",
    "coarseNE_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el mismo truco que utilizamos en los documentos para propagar los art_ID según corresponda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarseNE_0 = spread_artID(coarseNE_0)\n",
    "coarseNE_0 = coarseNE_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarseNE_0 contiene 257656 entidades.\n",
      "coarseNE_0 contiene 1810 artículos\n"
     ]
    }
   ],
   "source": [
    "print('coarseNE_0 contiene {} entidades.'.format(coarseNE_0.shape[0]))\n",
    "print('coarseNE_0 contiene {} artículos'.format(len(coarseNE_0['art_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuevas columnas con la info de la columna named-entity para mejor manipulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarseNE_0['named-entity'] = coarseNE_0['named-entity'].map(lambda x: x.split('\\t'))\n",
    "coarseNE_0['senIdx'] = coarseNE_0['named-entity'].map(lambda x: int(x[0]))\n",
    "coarseNE_0['begin'] = coarseNE_0['named-entity'].map(lambda x: int(x[1]))\n",
    "coarseNE_0['end'] = coarseNE_0['named-entity'].map(lambda x: int(x[2]))\n",
    "coarseNE_0['entityType'] = coarseNE_0['named-entity'].map(lambda x: get_tag(int(x[3])))\n",
    "coarseNE_0 = coarseNE_0.drop(columns='named-entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_ID</th>\n",
       "      <th>senIdx</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_ID  senIdx  begin  end entityType\n",
       "1  1000.0       0      0    2        PER\n",
       "2  1000.0       0      5    6        LOC\n",
       "3  1000.0       0     10   12        PER\n",
       "4  1000.0       1      2    4        PER\n",
       "5  1000.0       1      5    6        PER"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarseNE_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No todos los artículos que ocurren en Documents/0 se encuentran en CoarseNE/0\n",
    "\n",
    "Notar que esto sucede porque esos artículos no contienen entidades nombradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artículos que están presentes en Documents/0 pero no en CoarseNE/0: [431177.0, 432375.0, 432318.0, 10263.0]\n"
     ]
    }
   ],
   "source": [
    "print('Artículos que están presentes en Documents/0 pero no en CoarseNE/0: {}'\n",
    "      .format(list(set(doc_0.art_ID.unique()) - set(coarseNE_0.art_ID.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In economics , economics of location is a strategy used by firms in a monopolistic competition environment .\n",
      "Unlike a product differentiation strategy , where firms make their products different in order to attract customers , the economics of location strategy causes firms to produce similar or identical products .\n"
     ]
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 431177]\n",
    "for sentence in article.sentence.values:\n",
    "    dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "    print(' '.join(dec_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos como están anotadas las entidades nombradas de una oración en particular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercule Poirot is a fictional Belgian detective , created by Agatha Christie .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 1000]\n",
    "sentence = article.iloc[0, article.columns.get_loc('sentence')]\n",
    "dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "' '.join(dec_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_entities = coarseNE_0[coarseNE_0.art_ID == 1000]\n",
    "entities_sen_0 = art_entities[art_entities.senIdx == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hercule Poirot : PER\n",
      "Belgian : LOC\n",
      "Agatha Christie : PER\n"
     ]
    }
   ],
   "source": [
    "for idx, row in entities_sen_0.iterrows():\n",
    "    print('{} : {}'.format(' '.join(dec_sentence[row['begin']:row['end']]), row['entityType']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora utilicemos los dataframes preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Belton, House, is, a, Grade, I, listed, count...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, mansion, is, surrounded, by, formal, gar...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Belton, has, been, described, as, a, compilat...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, house, has, also, been, described, as, t...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Only, Brympton, d'Evercy, has, been, similarl...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "1  [Belton, House, is, a, Grade, I, listed, count...  145492.0\n",
       "2  [The, mansion, is, surrounded, by, formal, gar...  145492.0\n",
       "3  [Belton, has, been, described, as, a, compilat...  145492.0\n",
       "4  [The, house, has, also, been, described, as, t...  145492.0\n",
       "5  [Only, Brympton, d'Evercy, has, been, similarl...  145492.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc77_df = pd.read_pickle('./corpus_WiNER/docs_df/77')\n",
    "article_df = doc77_df[doc77_df.art_ID == 145492]\n",
    "dec_sentence = article_df.iloc[0, article_df.columns.get_loc('sentence')]\n",
    "doc77_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_ID</th>\n",
       "      <th>senIdx</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42515</th>\n",
       "      <td>145492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42516</th>\n",
       "      <td>145492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42517</th>\n",
       "      <td>145492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42518</th>\n",
       "      <td>145492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42519</th>\n",
       "      <td>145492.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         art_ID  senIdx  begin  end entityType\n",
       "42515  145492.0       0      0    2        LOC\n",
       "42516  145492.0       0     10   11        LOC\n",
       "42517  145492.0       0     12   13        LOC\n",
       "42518  145492.0       0     14   15        LOC\n",
       "42519  145492.0       0     16   17        LOC"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarseNE_77 = pd.read_pickle('./corpus_WiNER/coarseNE_df/77')\n",
    "art_entities_df = coarseNE_77[coarseNE_77.art_ID == 145492]\n",
    "sen_entities_0 = art_entities_df[art_entities_df.senIdx == 0]\n",
    "art_entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belton House : LOC\n",
      "Belton : LOC\n",
      "Grantham : LOC\n",
      "Lincolnshire : LOC\n",
      "England : LOC\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sen_entities_0.iterrows():\n",
    "    print('{} : {}'.format(' '.join(dec_sentence[row['begin']:row['end']]), row['entityType']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belton House is a Grade I listed country house in Belton near Grantham , Lincolnshire , England .\n",
      "['LOC', 'LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'LOC', 'O', 'LOC', 'O', 'LOC', 'O', 'LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "entity_list = entityListFromSentence(senIdx=0, sen_length=len(dec_sentence),\n",
    "                                     art_entities_df=art_entities_df)\n",
    "print(' '.join(article_df['sentence'][1]))\n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demora: 3.4760005474090576\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "wordVector_Entity_df = getVector_EntityFromArticle(article_df, art_entities_df, \n",
    "                                                   strategy='exp_decay',\n",
    "                                                   W=5, w2v_model=w2v_model)\n",
    "end = time.time()\n",
    "print('demora:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras: 4395\n",
      "Cantidad de entidades nombradas: 399\n",
      "Porcentaje de entidades nombradas: 9.08%\n"
     ]
    }
   ],
   "source": [
    "entity_list = list(wordVector_Entity_df['entityType'])\n",
    "tokens = len(entity_list)\n",
    "print('Cantidad de palabras: {}'.format(tokens))\n",
    "n_e = len(entity_list) - entity_list.count('O')\n",
    "print('Cantidad de entidades nombradas: {}'.format(n_e))\n",
    "print('Porcentaje de entidades nombradas: {:.2f}%'.format(n_e/tokens*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, cada artículo contiene una proporción reducida de palabras que son entidades.\n",
    "\n",
    "Una alternativa para evitar cómputo y uso de memoria podría ser eliminar una proporción de vectores que no representan ninguna entidad (etiquetados con 'O') a la hora de construir la matriz de palabra - entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordVector</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.003621502994722617, 0.012132806459215266, ...</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.08827082592044064, -0.13598437701614993, 0...</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.16997208299104571, 0.0033914764131283102, ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.3915967207881669, -0.12179563739202309, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.048302400391625866, -0.09540661652931712, 0...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.5453598294447486, -0.15736036498200667, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-0.12074501704763917, 0.06705739051063955, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-0.014825387882357826, -0.25825100262032796, ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.10727509902624327, 0.04387436488263421, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.07985290764610813, -0.14920335335911, -0.03...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordVector entityType\n",
       "0  [-0.003621502994722617, 0.012132806459215266, ...        LOC\n",
       "1  [-0.08827082592044064, -0.13598437701614993, 0...        LOC\n",
       "2  [-0.16997208299104571, 0.0033914764131283102, ...          O\n",
       "3  [-0.3915967207881669, -0.12179563739202309, 0....          O\n",
       "4  [0.048302400391625866, -0.09540661652931712, 0...          O\n",
       "5  [-0.5453598294447486, -0.15736036498200667, 0....          O\n",
       "6  [-0.12074501704763917, 0.06705739051063955, 0....          O\n",
       "7  [-0.014825387882357826, -0.25825100262032796, ...          O\n",
       "8  [-0.10727509902624327, 0.04387436488263421, 0....          O\n",
       "9  [0.07985290764610813, -0.14920335335911, -0.03...          O"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVector_Entity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordVector</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.003621502994722617, 0.012132806459215266, ...</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.08827082592044064, -0.13598437701614993, 0...</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.5453598294447486, -0.15736036498200667, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-0.12074501704763917, 0.06705739051063955, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.10727509902624327, 0.04387436488263421, 0....</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.07985290764610813, -0.14920335335911, -0.03...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          wordVector entityType\n",
       "0  [-0.003621502994722617, 0.012132806459215266, ...        LOC\n",
       "1  [-0.08827082592044064, -0.13598437701614993, 0...        LOC\n",
       "5  [-0.5453598294447486, -0.15736036498200667, 0....          O\n",
       "6  [-0.12074501704763917, 0.06705739051063955, 0....          O\n",
       "8  [-0.10727509902624327, 0.04387436488263421, 0....          O\n",
       "9  [0.07985290764610813, -0.14920335335911, -0.03...          O"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_non_entities(wordVector_Entity_df.head(10), 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División de los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los primeros 2000 documentos que van a ser utilizados para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_filenames, coarseNE_filenames = read_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df, coarseNE_df = load_docs(doc_filenames[0:2000], coarseNE_filenames[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones: 40865743\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de oraciones:', docs_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de artículos que no contienen ninguna entidad: 5376\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de artículos que no contienen ninguna entidad:', \n",
    "      len(docs_df.art_ID.unique()) - len(coarseNE_df.art_ID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con aquellos artículos que contienen al menos una entidad nombrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art_IDs = coarseNE_df.art_ID.unique() # Solo se ejecuta la primera vez sino no fueron guardados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraemos una muestra aleatoria de 1000 artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos los IDs de los articulos seleccionados en la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('../corpus_WiNER/art_IDs_sample_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_IDs_sample_train = pd.read_csv('../corpus_WiNER/art_IDs_sample_train.csv')\n",
    "art_IDs_sample_train = np.array(art_IDs_sample_train['art_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleamos nuevos art_IDs distintos a los cargados anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(art_IDs)\n",
    "art_IDs_sample = art_IDs\n",
    "art_IDs_sample_train_extra = [art_id for art_id in art_IDs_sample if art_id not in art_IDs_sample_train]\n",
    "art_IDs_sample_train_extra = art_IDs_sample_train_extra[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample_train_extra, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('../corpus_WiNER/art_IDs_sample_train_extra.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_IDs_sample_train_extra = pd.read_csv('../corpus_WiNER/art_IDs_sample_train_extra.csv')\n",
    "art_IDs_sample_train_extra = np.array(art_IDs_sample_train_extra['art_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_train)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20870, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:12,  2.06s/it]                      /home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "1000it [03:56,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo de guardado: 16.749330043792725\n",
      "Demora total: 253.8203845024109\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "genWordVectors_Entity(doc_df=articles_df, coarseNE_df=entities_df,\n",
    "                      strategy='exp_decay', W=5, w2v_model=w2v_model, splitType='train')\n",
    "end = time.time()\n",
    "print('Demora total: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de instancias utilizando una ventana simétrica de palabras que rodea a la palabra objetivo. \n",
    "\n",
    "Estas instancias van a ser utilizadas en los modelos: CNN y ladder CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_IDs_sample_train = pd.read_csv('../corpus_WiNER/art_IDs_sample_train.csv')\n",
    "art_IDs_sample_train = np.array(art_IDs_sample_train['art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [01:09, 43.28it/s]            \n",
      "62937it [00:34, 1811.03it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_cnn_instances(art_IDs_sample_train_extra, articles_df, entities_df, W=5, splitType='train_extra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los siguientes 600 documentos que se van a utilizar para VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_filenames, coarseNE_filenames = read_filenames()\n",
    "doc_filenames = doc_filenames[2000:2600]\n",
    "coarseNE_filenames = coarseNE_filenames[2000:2600]\n",
    "docs_df, coarseNE_df = load_docs(doc_filenames, coarseNE_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con aquellos artículos que contienen al menos una entidad nombrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art_IDs = coarseNE_df.art_ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraemos una muestra aleatoria de 250 artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:250]\n",
    "#### Guardamos los IDs de los articulos seleccionados en la muestra\n",
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('./corpus_WiNER/art_IDs_sample_dev.csv', index=False)\n",
    "#### Cargamos\n",
    "art_IDs_sample_dev = pd.read_csv('../corpus_WiNER/art_IDs_sample_dev.csv')\n",
    "art_IDs_sample_dev = np.array(art_IDs_sample_dev['art_ID'])\n",
    "#### Filtramos\n",
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_dev)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_dev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:11,  6.43it/s]                      /home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "250it [00:29,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo de guardado: 2.1902759075164795\n",
      "Demora total: 31.848532915115356\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "genWordVectors_Entity(doc_df=articles_df, coarseNE_df=entities_df,\n",
    "                      strategy='exp_decay', W=5, w2v_model=w2v_model, splitType='dev')\n",
    "end = time.time()\n",
    "print('Demora total: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:04, 58.82it/s]             \n",
      "2739it [00:00, 4333.38it/s]\n"
     ]
    }
   ],
   "source": [
    "## Generación de instancias utilizando una ventana simétrica de palabras que rodea a la palabra objetivo. \n",
    "# Estas instancias van a ser utilizadas en los modelos: CNN y ladder CNN.\n",
    "generate_cnn_instances(art_IDs_sample_dev, articles_df, entities_df, W=5, splitType='dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los siguientes 600 documentos que se van a utilizar para TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_filenames, coarseNE_filenames = read_filenames()\n",
    "doc_filenames = doc_filenames[2600:3200]\n",
    "coarseNE_filenames = coarseNE_filenames[2600:3200]\n",
    "docs_df, coarseNE_df = load_docs(doc_filenames, coarseNE_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con aquellos artículos que contienen al menos una entidad nombrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art_IDs = coarseNE_df.art_ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraemos una muestra aleatoria de 250 artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:250]\n",
    "#### Guardamos los IDs de los articulos seleccionados en la muestra\n",
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('./corpus_WiNER/art_IDs_sample_test.csv', index=False)\n",
    "#### Cargamos\n",
    "art_IDs_sample_test = pd.read_csv('../corpus_WiNER/art_IDs_sample_test.csv')\n",
    "art_IDs_sample_test = np.array(art_IDs_sample_test['art_ID'])\n",
    "#### Filtramos\n",
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_test)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233it [00:33,  7.52it/s]             /home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ekokic/env_thesis/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "250it [00:35,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiempo de guardado: 2.4580771923065186\n",
      "Demora total: 37.962523460388184\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "genWordVectors_Entity(doc_df=articles_df, coarseNE_df=entities_df,\n",
    "                      strategy='exp_decay', W=5, w2v_model=w2v_model, splitType='test')\n",
    "end = time.time()\n",
    "print('Demora total: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:04, 54.33it/s]             \n",
      "3243it [00:00, 4803.98it/s]\n"
     ]
    }
   ],
   "source": [
    "## Generación de instancias utilizando una ventana simétrica de palabras que rodea a la palabra objetivo. \n",
    "# Estas instancias van a ser utilizadas en los modelos: CNN y ladder CNN.\n",
    "generate_cnn_instances(art_IDs_sample_test, articles_df, entities_df, W=5, splitType='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la distribución de la longitud de las oraciones para decidir un tamaño donde truncar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_df.to_csv('art_df_seq_tag_train.csv', index=False)\n",
    "# entities_df.to_csv('ent_df_seq_tag_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Human, anatomy, -LRB-, gr, .]</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ἀνατομία, ,, ``, dissection, '', ,, from, ἀνά...</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Anatomy, is, subdivided, into, gross, anatomy...</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Gross, anatomy, -LRB-, also, called, topograp...</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Microscopic, anatomy, is, the, study, of, min...</td>\n",
       "      <td>13268.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   art_ID\n",
       "0                     [Human, anatomy, -LRB-, gr, .]  13268.0\n",
       "1  [ἀνατομία, ,, ``, dissection, '', ,, from, ἀνά...  13268.0\n",
       "2  [Anatomy, is, subdivided, into, gross, anatomy...  13268.0\n",
       "3  [Gross, anatomy, -LRB-, also, called, topograp...  13268.0\n",
       "4  [Microscopic, anatomy, is, the, study, of, min...  13268.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df = pd.read_csv('art_df_seq_tag_train.csv')\n",
    "# https://stackoverflow.com/questions/1894269/convert-string-representation-of-list-to-list\n",
    "import ast\n",
    "articles_df['sentence'] = articles_df.sentence.map(lambda sen: ast.literal_eval(sen))\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones para train: 20870\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de oraciones para train:', articles_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['sen_length'] = articles_df.sentence.apply(lambda sen: len(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "      <th>sen_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Human, anatomy, -LRB-, gr, .]</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ἀνατομία, ,, ``, dissection, '', ,, from, ἀνά...</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Anatomy, is, subdivided, into, gross, anatomy...</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Gross, anatomy, -LRB-, also, called, topograp...</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Microscopic, anatomy, is, the, study, of, min...</td>\n",
       "      <td>13268.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   art_ID  sen_length\n",
       "0                     [Human, anatomy, -LRB-, gr, .]  13268.0           5\n",
       "1  [ἀνατομία, ,, ``, dissection, '', ,, from, ἀνά...  13268.0          33\n",
       "2  [Anatomy, is, subdivided, into, gross, anatomy...  13268.0          10\n",
       "3  [Gross, anatomy, -LRB-, also, called, topograp...  13268.0          29\n",
       "4  [Microscopic, anatomy, is, the, study, of, min...  13268.0          35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekokic/miniconda3/envs/thesis-tf-gpu/lib/python3.5/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "ax = sns.distplot(list(articles_df.sen_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length mean: 24.315189266890272\n",
      "Sentence length median: 22.0\n"
     ]
    }
   ],
   "source": [
    "print('Sentence length mean:', np.mean(articles_df.sen_length))\n",
    "print('Sentence length median:', np.median(articles_df.sen_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision experimental: Se tomara max_len_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_ID</th>\n",
       "      <th>senIdx</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12946.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    art_ID  senIdx  begin  end entityType\n",
       "0  12946.0       0      0    3        PER\n",
       "1  12946.0       0      5    6        PER\n",
       "2  12946.0       1      5    8        ORG\n",
       "3  12946.0       1      9   14        LOC\n",
       "4  12946.0       2      3    4       MISC"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df = pd.read_csv('ent_df_seq_tag_train.csv')\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4870it [02:11, 36.94it/s]                    \n"
     ]
    }
   ],
   "source": [
    "doc_filenames, coarseNE_filenames = read_filenames()\n",
    "docs_df, coarseNE_df = load_docs(doc_filenames[0:2000], coarseNE_filenames[0:2000])\n",
    "# art_IDs = coarseNE_df.art_ID.unique() # Solo se ejecuta la primera vez sino no fueron guardados\n",
    "# # Extraemos una muestra aleatoria de n artículos\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:5000]\n",
    "# # Guardamos los IDs de los articulos seleccionados en la muestra\n",
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('../corpus_WiNER/art_IDs_seq_tag_sample_train.csv', index=False)\n",
    "art_IDs_sample_train = pd.read_csv('../corpus_WiNER/art_IDs_seq_tag_sample_train.csv')\n",
    "art_IDs_sample_train = np.array(art_IDs_sample_train['art_ID'])\n",
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_train)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_train)]\n",
    "print('Cantidad de oraciones:', articles_df.shape[0])\n",
    "generate_seq_tag_instances(articles_df[:100000], entities_df, max_sen_length=30, splitType='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 69.18it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones: 21931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1812it [00:28, 63.77it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_filenames, coarseNE_filenames = read_filenames()\n",
    "docs_df, coarseNE_df = load_docs(doc_filenames[2000:2600], coarseNE_filenames[2000:2600])\n",
    "# art_IDs = coarseNE_df.art_ID.unique() # Solo se ejecuta la primera vez sino no fueron guardados\n",
    "# # Extraemos una muestra aleatoria de n artículos\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:2000]\n",
    "# # Guardamos los IDs de los articulos seleccionados en la muestra\n",
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('../corpus_WiNER/art_IDs_seq_tag_sample_dev.csv', index=False)\n",
    "art_IDs_sample_dev = pd.read_csv('../corpus_WiNER/art_IDs_seq_tag_sample_dev.csv')\n",
    "art_IDs_sample_dev = np.array(art_IDs_sample_dev['art_ID'])\n",
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_dev)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_dev)]\n",
    "print('Cantidad de oraciones:', articles_df.shape[0])\n",
    "generate_seq_tag_instances(articles_df[:20000], entities_df, max_sen_length=30, splitType='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 87.62it/s]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones: 24436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1661it [00:27, 59.57it/s]\n"
     ]
    }
   ],
   "source": [
    "_seq_tagdoc_filenames, coarseNE_filenames = read_filenames()\n",
    "docs_df, coarseNE_df = load_docs(doc_filenames[2600:3200], coarseNE_filenames[2600:3200])\n",
    "# art_IDs = coarseNE_df.art_ID.unique() # Solo se ejecuta la primera vez sino no fueron guardados\n",
    "# # Extraemos una muestra aleatoria de n artículos\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(art_IDs)\n",
    "# art_IDs_sample = art_IDs[0:2000]\n",
    "# # Guardamos los IDs de los articulos seleccionados en la muestra\n",
    "# art_IDs_sample_df = pd.DataFrame(data=art_IDs_sample, columns=['art_ID'])\n",
    "# art_IDs_sample_df.to_csv('../corpus_WiNER/art_IDs_seq_tag_sample_test.csv', index=False)\n",
    "art_IDs_sample_test = pd.read_csv('../corpus_WiNER/art_IDs_seq_tag_sample_test.csv')\n",
    "art_IDs_sample_test = np.array(art_IDs_sample_test['art_ID'])\n",
    "articles_df = docs_df[docs_df.art_ID.isin(art_IDs_sample_test)]\n",
    "entities_df = coarseNE_df[coarseNE_df.art_ID.isin(art_IDs_sample_test)]\n",
    "print('Cantidad de oraciones:', articles_df.shape[0])\n",
    "generate_seq_tag_instances(articles_df[:20000], entities_df, max_sen_length=30, splitType='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
