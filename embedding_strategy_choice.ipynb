{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y Preprocesamiento (continuación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento: se utilizarán 3 modelos distintos (LR - Linear SVM - MLP) utilizando los datos anotados de las muestras de vectores de palabras generados luego de aplicar las 4 estrategias de representación que se estudiaron en el trabajo de Iacobacci. Se evaluará la performance con el objetivo de seleccionar la mejor estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, GlobalMaxPooling1D, Input, concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Activation\n",
    "from keras import backend as K\n",
    "from keras import optimizers, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.load('./corpus_WiNER/word_vectors/wv_sample_exp_decay_W_5.npz')\n",
    "entity_vector = np.load('./corpus_WiNER/entity_vectors/ev_sample_exp_decay_W_5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# word vectors: 518696\n",
      "# non entities 273639\n",
      "['MISC', 'MISC', 'O', 'O', 'ORG', 'ORG', 'MISC', 'MISC', 'O', 'MISC']\n"
     ]
    }
   ],
   "source": [
    "entities = list(entity_vector.items()[0][1])\n",
    "print('# word vectors:', len(entities))\n",
    "print('# non entities', entities.count('O'))\n",
    "print(entities[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518696\n",
      "518696\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vectors.items()[0][1]))\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos los datos en train - dev - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 414956\n",
      "#dev: 51870\n",
      "#test: 51870\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(word_vectors.items()[0][1], entities,\n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.11111, \n",
    "                                                  random_state=42)\n",
    "print('#train:', len(X_train))\n",
    "print('#dev:', len(X_dev))\n",
    "print('#test:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'clf__random_state': [0],\n",
    "    # parameter for LogisticRegression (smaller values -> stronger regularization)\n",
    "    'clf__C': [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "}\n",
    "params_list = list(ParameterGrid(param_grid))\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return {'acc': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.6209176788124157, 'f1': 0.4848253961688366}\n",
      "{'acc': 0.6270676691729323, 'f1': 0.5034629240863471}\n",
      "{'acc': 0.6274339695392327, 'f1': 0.5053202449733059}\n",
      "{'acc': 0.627549643339117, 'f1': 0.5057058268923362}\n",
      "{'acc': 0.6276267592057065, 'f1': 0.5059113812011955}\n",
      "{'acc': 0.6277231540389435, 'f1': 0.5060280162201334}\n",
      "{'acc': 0.6278002699055331, 'f1': 0.5061783535668727}\n",
      "{'acc': 0.6278002699055331, 'f1': 0.5062461635037615}\n",
      "{'acc': 0.6278002699055331, 'f1': 0.5062461635037615}\n",
      "{'acc': 0.6278002699055331, 'f1': 0.5062461635037615}\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "results = []\n",
    "for params in params_list:\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    result = evaluate(pipeline, X_dev, y_dev)\n",
    "    print(result)\n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.627800</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.627800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.627800</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.627800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.627723</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.627627</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.627550</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.627434</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.627068</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620918</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  clf__C  clf__random_state        f1\n",
       "7  0.627800   2.000                  0  0.506246\n",
       "8  0.627800   5.000                  0  0.506246\n",
       "9  0.627800  10.000                  0  0.506246\n",
       "6  0.627800   1.000                  0  0.506178\n",
       "5  0.627723   0.500                  0  0.506028\n",
       "4  0.627627   0.300                  0  0.505911\n",
       "3  0.627550   0.100                  0  0.505706\n",
       "2  0.627434   0.050                  0  0.505320\n",
       "1  0.627068   0.010                  0  0.503463\n",
       "0  0.620918   0.001                  0  0.484825"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, y_train_small = X_train[:8000], y_train[:8000]\n",
    "X_dev_small, y_dev_small = X_dev[:1000], y_dev[:1000]\n",
    "X_test_small, y_test_small = X_test[:1000], y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train_small, y_train_small)\n",
    "results = evaluate(model, X_dev_small, y_dev_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.616, 'f1': 0.4821340726272302}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probemos con un Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(word_vectors.items()[0][1], entities,\n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466826\n",
      "51870\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'PER', 'O', 'LOC', 'MISC', 'O', 'ORG', 'O', 'O', 'ORG']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagToInt(tag):\n",
    "    return {'O': 0, 'PER': 1, 'ORG': 2, 'LOC': 3, 'MISC': 4}[tag]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [tagToInt(y) for y in y_train]\n",
    "y_test = [tagToInt(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 3, 4, 0, 2, 0, 0, 2]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10] # this transformation is needed to apply to_categorical() keras method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512  # For mini-batch gradient descent\n",
    "num_classes = 5 # PER - LOC - ORG - MISC - O\n",
    "epochs = 10\n",
    "input_size = 300 # word vectors dimensionality\n",
    "train_examples = 466826 # len(X_train)\n",
    "test_examples = 51870 # len(X_test)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466826, 300)\n",
      "(466826, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466826, 300)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = 300 # ????\n",
    "channels = 1\n",
    "input_shape = (steps, channels) #3D tensor with shape: `(batch, steps, channels)`\n",
    "# # Output shape\n",
    "#     3D tensor with shape: `(batch, new_steps, filters)`\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466826, 300, 1)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model TODO: cambiar y utilizar MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "conv_filters = 10\n",
    "pool_size = 3\n",
    "inp = Input(shape=(X_train.shape[1],1), dtype='float64')\n",
    "print(inp.shape)\n",
    "# Specify each convolution layer and their kernel size i.e. n-grams \n",
    "conv1_1 = Conv1D(filters=conv_filters, kernel_size=3, activation='relu')(inp)\n",
    "btch1_1 = BatchNormalization()(conv1_1)\n",
    "maxp1_1 = MaxPooling1D(pool_size=pool_size)(btch1_1)\n",
    "flat1_1 = Flatten()(maxp1_1)\n",
    "\n",
    "conv1_2 = Conv1D(filters=conv_filters, kernel_size=4, activation='relu')(inp)\n",
    "btch1_2 = BatchNormalization()(conv1_2)\n",
    "maxp1_2 = MaxPooling1D(pool_size=pool_size)(btch1_2)\n",
    "flat1_2 = Flatten()(maxp1_2)\n",
    "\n",
    "conv1_3 = Conv1D(filters=conv_filters, kernel_size=5, activation='relu')(inp)\n",
    "btch1_3 = BatchNormalization()(conv1_3)\n",
    "maxp1_3 = MaxPooling1D(pool_size=pool_size)(btch1_3)\n",
    "flat1_3 = Flatten()(maxp1_3)\n",
    "\n",
    "# Gather all convolution layers\n",
    "cnct = concatenate([flat1_1, flat1_2, flat1_3], axis=1)\n",
    "drp1 = Dropout(0)(cnct)\n",
    "\n",
    "dns1  = Dense(128, activation='relu')(drp1)\n",
    "out = Dense(num_classes, activation='softmax')(dns1)#(drp2)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, 300, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 298, 10)      40          input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 297, 10)      50          input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 296, 10)      60          input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 298, 10)      40          conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 297, 10)      40          conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 296, 10)      40          conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 99, 10)       0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 99, 10)       0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 98, 10)       0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 990)          0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 990)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 980)          0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 2960)         0           flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 2960)         0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 128)          379008      dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 5)            645         dense_56[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 379,923\n",
      "Trainable params: 379,863\n",
      "Non-trainable params: 60\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420143 samples, validate on 46683 samples\n",
      "Epoch 1/10\n",
      "420143/420143 [==============================] - 53s 127us/step - loss: 0.9915 - acc: 0.6318 - val_loss: 0.9237 - val_acc: 0.6507\n",
      "Epoch 2/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.8870 - acc: 0.6644 - val_loss: 0.8983 - val_acc: 0.6612\n",
      "Epoch 3/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.8524 - acc: 0.6783 - val_loss: 0.9042 - val_acc: 0.6604\n",
      "Epoch 4/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.8257 - acc: 0.6892 - val_loss: 0.9068 - val_acc: 0.6583\n",
      "Epoch 5/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: 0.8024 - acc: 0.6981 - val_loss: 0.8797 - val_acc: 0.6735\n",
      "Epoch 6/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7813 - acc: 0.7062 - val_loss: 0.8940 - val_acc: 0.6648\n",
      "Epoch 7/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7609 - acc: 0.7148 - val_loss: 0.8924 - val_acc: 0.6677\n",
      "Epoch 8/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7419 - acc: 0.7220 - val_loss: 0.8947 - val_acc: 0.6695\n",
      "Epoch 9/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7245 - acc: 0.7287 - val_loss: 0.9099 - val_acc: 0.6684\n",
      "Epoch 10/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7077 - acc: 0.7349 - val_loss: 0.9169 - val_acc: 0.6701\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia: Decaimiento Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9030835823008888\n",
      "Test accuracy: 0.674146905714362\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia: Decaimiento Fraccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.load('./corpus_WiNER/word_vectors/wv_sample_frac_decay_W_5.npz')\n",
    "entity_vector = np.load('./corpus_WiNER/entity_vectors/ev_sample_frac_decay_W_5.npz')\n",
    "word_vecs = word_vectors.items()[0][1]\n",
    "entities = list(entity_vector.items()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_vecs, entities,\n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)\n",
    "y_train = [tagToInt(y) for y in y_train]\n",
    "y_test = [tagToInt(y) for y in y_test]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420143 samples, validate on 46683 samples\n",
      "Epoch 1/10\n",
      "420143/420143 [==============================] - 53s 126us/step - loss: 0.7438 - acc: 0.7184 - val_loss: 0.9465 - val_acc: 0.6536\n",
      "Epoch 2/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7227 - acc: 0.7271 - val_loss: 0.9482 - val_acc: 0.6534\n",
      "Epoch 3/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.7040 - acc: 0.7346 - val_loss: 0.9809 - val_acc: 0.6473\n",
      "Epoch 4/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6884 - acc: 0.7410 - val_loss: 0.9988 - val_acc: 0.6436\n",
      "Epoch 5/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6728 - acc: 0.7467 - val_loss: 0.9936 - val_acc: 0.6484\n",
      "Epoch 6/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6585 - acc: 0.7527 - val_loss: 1.0047 - val_acc: 0.6462\n",
      "Epoch 7/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: 0.6447 - acc: 0.7579 - val_loss: 1.0400 - val_acc: 0.6419\n",
      "Epoch 8/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6304 - acc: 0.7631 - val_loss: 1.0592 - val_acc: 0.6421\n",
      "Epoch 9/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6181 - acc: 0.7683 - val_loss: 1.0628 - val_acc: 0.6396\n",
      "Epoch 10/10\n",
      "420143/420143 [==============================] - 51s 122us/step - loss: 0.6056 - acc: 0.7734 - val_loss: 1.0829 - val_acc: 0.6413\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0672896337389648\n",
      "Test accuracy: 0.6471563524126156\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia: Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.load('./corpus_WiNER/word_vectors/wv_sample_mean_W_5.npz')\n",
    "entity_vector = np.load('./corpus_WiNER/entity_vectors/ev_sample_mean_W_5.npz')\n",
    "word_vecs = word_vectors.items()[0][1]\n",
    "entities = list(entity_vector.items()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(word_vecs, entities,\n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)\n",
    "y_train = [tagToInt(y) for y in y_train]\n",
    "y_test = [tagToInt(y) for y in y_test]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420143 samples, validate on 46683 samples\n",
      "Epoch 1/10\n",
      "420143/420143 [==============================] - 52s 125us/step - loss: nan - acc: 0.5471 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 2/10\n",
      "420143/420143 [==============================] - 50s 120us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 3/10\n",
      "420143/420143 [==============================] - 50s 120us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 4/10\n",
      "420143/420143 [==============================] - 51s 120us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 5/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 6/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 7/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 8/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 9/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n",
      "Epoch 10/10\n",
      "420143/420143 [==============================] - 51s 121us/step - loss: nan - acc: 0.5273 - val_loss: nan - val_acc: 0.5293\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: nan\n",
      "Test accuracy: 0.5277038750860855\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión: la estrategia de Decaimiento Exponencial parece ser la más apropiada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
