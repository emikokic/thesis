{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se explorarán, en pequeños experimentos, distintas formas de representación de los datos del corpus WiNER (Ghaddar y Langlais 2017) para utilizarlos en la tarea de reconocimiento de entidades nombradas. Para esto se exploran distintas combinaciones de vectores de palabras como representación de una instancia de entrenamiento (Iacobacci et al. 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del Corpus WiNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documents.tar.bz2 : este archivo contiene 3239540 artículos de Wikipedia repartidos en 3223 archivos. Cada archivo contiene aproximadamente 1000 artículos nombrados por sus respectivos IDs. Los artículos están indexados por su wikiID seguidos de oraciones (una por línea), donde las palabras son remplazadas por sus ids.\n",
    "\n",
    "      ID <number>\n",
    "      1234 4522 23 4 4567\n",
    "      456 21 9890 123 7 0\n",
    "\n",
    "* document.vocab : este archivo contiene el mapeo de palabras (case sensitive); el formato es: \n",
    " \n",
    "      palabra #ocurrencias\n",
    "    \n",
    "  El ID de cada palabra es el número de línea en la cual ocurre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mapping = pd.read_csv('./corpus_WiNER/document.vocab', sep=' ', header=None, \n",
    "                           names=['word', 'frequency'], keep_default_na=False) \n",
    "                        # con esto evito que el parser trate como nan value a algunas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6931358, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>73411953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>68044881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>54241850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>40550466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>34602894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  frequency\n",
       "0  the   73411953\n",
       "1    ,   68044881\n",
       "2    .   54241850\n",
       "3   of   40550466\n",
       "4  and   34602894"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_mapping.shape)\n",
    "word_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6931358"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_mapping['word'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los artículos del Documento \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = pd.read_csv('./corpus_WiNER/Documents/0', sep='ID', engine='python', header=None, names=['sentence', 'art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130209, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650 5590 753942 12 189 243 1 2039 47 257 682 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34 23207 1523 4 57193 15 10777 14353 4 157019 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "0                                                NaN  431388.0\n",
       "1  650 5590 753942 12 189 243 1 2039 47 257 682 1...       NaN\n",
       "2  34 23207 1523 4 57193 15 10777 14353 4 157019 ...       NaN\n",
       "3  418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...       NaN\n",
       "4  650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a asociarle a cada oración el ID del artículo al cual pertenece.\n",
    "\n",
    "Es importante recordar que el orden de las oraciones está dado por los índices del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_ID_list = doc_0['art_ID'].tolist()\n",
    "art_ID = 0\n",
    "for idx, elem in enumerate(art_ID_list):\n",
    "    if not np.isnan(elem):\n",
    "        art_ID = elem\n",
    "    else:\n",
    "        art_ID_list[idx] = art_ID\n",
    "doc_0['art_ID'] = art_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos ahora las filas con NaN que contenian los ID de los artículos inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = doc_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento contiene 128395 oraciones.\n",
      "El documento contiene 1814 artículos\n"
     ]
    }
   ],
   "source": [
    "print('El documento contiene {} oraciones.'.format(doc_0.shape[0]))\n",
    "print('El documento contiene {} artículos'.format(len(doc_0['art_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos que cada sentencia sea una lista de palabras codificadas y casteamos a int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0['sentence'] = doc_0['sentence'].map(lambda x: list(map(int, x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "1  [650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...  431388.0\n",
       "2  [34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...  431388.0\n",
       "3  [418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...  431388.0\n",
       "4  [650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...  431388.0\n",
       "5  [152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...  431388.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con un artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>[63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>[3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>[24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>[152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>[64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  art_ID\n",
       "2756  [63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...  1000.0\n",
       "2757  [3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...  1000.0\n",
       "2758  [24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...  1000.0\n",
       "2759  [152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...  1000.0\n",
       "2760  [64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...  1000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 1000]\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruimos la primera oración del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_decoder(sentence, word_mapping):\n",
    "    dec_sentence = []\n",
    "    for idx in sentence:\n",
    "        mapped_w = word_mapping.loc[idx, 'word']\n",
    "        dec_sentence.append(mapped_w)\n",
    "    return dec_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos article.columns.get_loc('sentence') para evitar hardcodear el índice correspondiente\n",
    "# a la columna 'sentence' que en este caso es 0\n",
    "sentence = article.iloc[0, article.columns.get_loc('sentence')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercule Poirot is a fictional Belgian detective , created by Agatha Christie .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "' '.join(dec_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings utilizando el modelo pre-entrenado word2vec de Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la librería Gensim https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos Google's pre-trained Word2Vec model.\n",
    "\n",
    "Utilizando KeyedVectors para cargar el modelo tiene la desventaja de que no se puede seguir entrenando. Pero es más eficiente que utilizar gensim.models.Word2Vec\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demora: 12.730851888656616\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# model = KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# model.save('./models/word2vecGoogle.model')\n",
    "model = KeyedVectors.load('./models/word2vecGoogle.model')\n",
    "end = time.time()\n",
    "print('demora: {}'.format(end-start))\n",
    "# model = Word2Vec.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de word embeddings: 3000000\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de word embeddings: {}'.format(len(model.vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidad de los vectores: 300\n"
     ]
    }
   ],
   "source": [
    "print('Dimensionalidad de los vectores: {}'.format(model.vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos distintas combinaciones de vectores de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación\n",
    "\n",
    "Este método consiste en concatenar los vectores de palabras que rodean una palabra objetivo en un vector más grande, que tiene un tamaño igual a las dimensiones agregadas de todos las proyecciones (embeddings) individuales.\n",
    "\n",
    "- $w_{ij}$ = peso asociado con la i-ésima dimensión del vector de la j-ésima palabra en la oración. NOTA: con los vectores de palabras de una oración se forma una matriz $w^{\\space D\\space x\\space L}$ donde $L$ es la cantidad de palabras de esa oración.\n",
    "- $D$ = dimensionalidad de los word vectors originales. Por ejemplo, al usar el modelo word2vec de Google sabemos que D = 300.\n",
    "- $W$ = tamaño de ventana que se define como el número de palabras en un solo lado.\n",
    "\n",
    "Nos interesa representar el contexto de la I-ésima palabra de la oración. \n",
    "\n",
    "La i-ésima dimensión del vector de concatenación, que tiene un tamaño de $2 W D$, se calcula de la siguiente manera:\n",
    "\n",
    "$$ e_{i} =\\begin{cases} \n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor < W \\\\\n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space 1\\space  +\\space\\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & c.c.\n",
    "   \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promedio\n",
    "\n",
    "Como su nombre indica, se calcula el centroide de los embeddings de todas las palabras circundantes. La fórmula divide cada dimensión en $2W$ ya que el número de palabras del contexto es dos veces el tamaño de la ventana:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} \\frac{w_{ij}}{2W}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento fraccional\n",
    "\n",
    "Una tercera estrategia para construir un vector de carácteristicas en base a los embeddings de palabras contextuales está inspirada en la forma en que Word2vec combina las palabras en el contexto. Aquí, se supone que la importancia de una palabra para nuestra representación es inversamente proporcional a su distancia respecto a la palabra objetivo.\n",
    "\n",
    "Por lo tanto, las palabras contextuales se ponderan en función de su distancia de la palabra objetivo:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} *\\frac{W - \\lvert I-j\\rvert}{W}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento exponencial\n",
    "\n",
    "Funciona de manera similar al decaimiento fraccional, que le da más importancia al contexto cercano, pero en este caso la ponderación se realiza exponencialmente:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} * (1 - \\alpha)^{\\lvert \\space I\\space-\\space j\\space\\rvert\\space-\\space1}$$\n",
    "\n",
    "donde $\\alpha = 1 - 0.1^{(W-1)^{-1}}$ es el parámetro de decaimiento. Elegimos el parámetro de tal manera que las palabras inmediatas que rodean a la palabra objetivo contribuyen 10 veces más que las últimas palabras en ambos lados de la ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: cambiar redacción y fórmulas de las distintas estrategias si se decide incluir al vector de la palabra objetivo en las operaciones que generan el nuevo vector.\n",
    "\n",
    "Agregar también que para el caso de concatenación se va a realizar padding de 0's a izquierda o derecha cuando corresponda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos CoarseNE.tar.bz2\n",
    "\n",
    "Contiene menciones anotadas automáticamente con etiquetas de entidades nombradas (PER, LOC, ORG y MISC).\n",
    "\n",
    "El formato es:\n",
    "\n",
    "    ID artID\n",
    "    sentIdx begin end entityType\n",
    "    \n",
    "donde entityType[0] = PER | entityType[1] = LOC | entityType[2] = ORG | entityType[3] = MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarseNE_0 = pd.read_csv('./corpus_WiNER/CoarseNE/0', sep='ID', engine='python', header=None, names=['named-entity', 'art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259470, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>named-entity</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t0\\t2\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t5\\t6\\t1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t10\\t12\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1\\t2\\t4\\t0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   named-entity  art_ID\n",
       "0           NaN  1000.0\n",
       "1    0\\t0\\t2\\t0     NaN\n",
       "2    0\\t5\\t6\\t1     NaN\n",
       "3  0\\t10\\t12\\t0     NaN\n",
       "4    1\\t2\\t4\\t0     NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(coarseNE_0.shape)\n",
    "coarseNE_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el mismo truco que utilizamos en los documentos para propagar los art_ID según corresponda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_ID_list = coarseNE_0['art_ID'].tolist()\n",
    "art_ID = 0\n",
    "for idx, elem in enumerate(art_ID_list):\n",
    "    if not np.isnan(elem):\n",
    "        art_ID = elem\n",
    "    else:\n",
    "        art_ID_list[idx] = art_ID\n",
    "coarseNE_0['art_ID'] = art_ID_list\n",
    "coarseNE_0 = coarseNE_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarseNE_0 contiene 257656 entidades.\n",
      "coarseNE_0 contiene 1810 artículos\n"
     ]
    }
   ],
   "source": [
    "print('coarseNE_0 contiene {} entidades.'.format(coarseNE_0.shape[0]))\n",
    "print('coarseNE_0 contiene {} artículos'.format(len(coarseNE_0['art_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No todos los artículos que ocurren en Documents/0 se encuentran en CoarseNE/0\n",
    "\n",
    "TODO: chequear si esto sucede porque esos artículos no contienen entidades nombradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artículos que están presentes en Documents/0 pero no en CoarseNE/0: [431177.0, 432375.0, 432318.0, 10263.0]\n"
     ]
    }
   ],
   "source": [
    "print('Artículos que están presentes en Documents/0 pero no en CoarseNE/0: {}'\n",
    "      .format(list(set(doc_0.art_ID.unique()) - set(coarseNE_0.art_ID.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuevas columnas con la info de la columna named-entity para mejor manipulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(x):\n",
    "    tags = ['PER', 'LOC', 'ORG', 'MISC']\n",
    "    return tags[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarseNE_0['named-entity'] = coarseNE_0['named-entity'].map(lambda x: x.split('\\t'))\n",
    "coarseNE_0['senIdx'] = coarseNE_0['named-entity'].map(lambda x: int(x[0]))\n",
    "coarseNE_0['begin'] = coarseNE_0['named-entity'].map(lambda x: int(x[1]))\n",
    "coarseNE_0['end'] = coarseNE_0['named-entity'].map(lambda x: int(x[2]))\n",
    "coarseNE_0['entityType'] = coarseNE_0['named-entity'].map(lambda x: get_tag(int(x[3])))\n",
    "coarseNE_0 = coarseNE_0.drop(columns='named-entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_ID</th>\n",
       "      <th>senIdx</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_ID  senIdx  begin  end entityType\n",
       "1  1000.0       0      0    2        PER\n",
       "2  1000.0       0      5    6        LOC\n",
       "3  1000.0       0     10   12        PER\n",
       "4  1000.0       1      2    4        PER\n",
       "5  1000.0       1      5    6        PER"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarseNE_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos como están anotadas las entidades nombradas de una oración en particular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercule Poirot is a fictional Belgian detective , created by Agatha Christie .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 1000]\n",
    "sentence = article.iloc[0, article.columns.get_loc('sentence')]\n",
    "dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "' '.join(dec_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_ID</th>\n",
       "      <th>senIdx</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>entityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_ID  senIdx  begin  end entityType\n",
       "1  1000.0       0      0    2        PER\n",
       "2  1000.0       0      5    6        LOC\n",
       "3  1000.0       0     10   12        PER"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_entities = coarseNE_0[coarseNE_0.art_ID == 1000]\n",
    "entities_sen_0 = art_entities[art_entities.senIdx == 0]\n",
    "entities_sen_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hercule Poirot : PER\n",
      "Belgian : LOC\n",
      "Agatha Christie : PER\n"
     ]
    }
   ],
   "source": [
    "for idx, row in entities_sen_0.iterrows():\n",
    "    print('{} : {}'.format(' '.join(dec_sentence[row['begin']:row['end']]), row['entityType']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas:\n",
    "\n",
    "- En las cuatro estrategias que plantea el paper, el vector de contexto que se genera no considera la información de la palabra objetivo (i.e. no se tiene en cuenta el vector objetivo para generar este nuevo vector). Sería mejor incluir el vector de la palabra objetivo para que la representación sea más informativa?\n",
    "\n",
    "<br>\n",
    "- Los experimentos para medir cuales representaciones funcionan mejor recién se van a poder realizar cuando tengamos la implementación de la red, verdad?\n",
    "\n",
    "<br>\n",
    "- Charlar sobre diseño del cargado y manipulación del Corpus. (mapeos, futura partición de datos para entrenamiento supervisado y no supervisado, etc)\n",
    "\n",
    "NOTA: \n",
    "      #articulos de CoarseNE/0 < #articulos de Documents/0\n",
    "      #articulos de CoarseNE/1 == #articulos de Documents/1 (y son los mismos)\n",
    "      \n",
    "      Tanto el dir CoarseNE como Documents contienen 3223 archivos\n",
    "      \n",
    "Es raro que el archivo 0 de ambos difiera en 4 la cantidad de articulos que posee.\n",
    "Sera porque justo esos 4 articulos no poseen ninguna entidad nombrada?\n",
    "TODO: chequear esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle(\"./doc_77\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Belton, House, is, a, Grade, I, listed, count...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, mansion, is, surrounded, by, formal, gar...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Belton, has, been, described, as, a, compilat...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, house, has, also, been, described, as, t...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Only, Brympton, d'Evercy, has, been, similarl...</td>\n",
       "      <td>145492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "1  [Belton, House, is, a, Grade, I, listed, count...  145492.0\n",
       "2  [The, mansion, is, surrounded, by, formal, gar...  145492.0\n",
       "3  [Belton, has, been, described, as, a, compilat...  145492.0\n",
       "4  [The, house, has, also, been, described, as, t...  145492.0\n",
       "5  [Only, Brympton, d'Evercy, has, been, similarl...  145492.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Belton House is a Grade I listed country house in Belton near Grantham , Lincolnshire , England .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(unpickled_df.loc[1, 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de oraciones: 54607542\n",
    "Cantidad de artículos: 3239540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
