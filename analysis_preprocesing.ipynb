{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se explorarán, en pequeños experimentos, distintas formas de representación de los datos del corpus WiNER (Ghaddar y Langlais 2017) para utilizarlos en la tarea de reconocimiento de entidades nombradas. Para esto se exploran distintas combinaciones de vectores de palabras como representación de una instancia de entrenamiento (Iacobacci et al. 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del Corpus WiNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Documents.tar.bz2 : este archivo contiene 3256489 (TODO: check this!) artículos de Wikipedia repartidos en 3225 archivos. Cada archivo contiene aproximadamente 1000 artículos nombrados por sus respectivos IDs. Los artículos están indexados por su wikiID seguidos de oraciones (una por línea), donde las palabras son remplazadas por sus ids.\n",
    "\n",
    "<br>\n",
    "* document.vocab : este archivo contiene el mapeo de palabras (case sensitive); el formato es: \n",
    "           palabra <espacio> #ocurrencias\n",
    "  El ID de cada palabra es el número de línea en la cual ocurre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mapping = pd.read_csv('./corpus_WiNER/document.vocab', sep=' ', header=None,\n",
    "                           keep_default_na=False) # con esto evito que el parser trate como \n",
    "                                                  # nan value a algunas palabras.\n",
    "word_mapping.columns = ['word', 'frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6931358, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>73411953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>68044881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>54241850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>40550466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>34602894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  frequency\n",
       "0  the   73411953\n",
       "1    ,   68044881\n",
       "2    .   54241850\n",
       "3   of   40550466\n",
       "4  and   34602894"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_mapping.shape)\n",
    "word_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6931358"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_mapping['word'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los artículos del Documento \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = pd.read_csv('./corpus_WiNER/Documents/0', sep='ID', engine='python', header=None, names=['sentence', 'art_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130209, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650 5590 753942 12 189 243 1 2039 47 257 682 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34 23207 1523 4 57193 15 10777 14353 4 157019 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "0                                                NaN  431388.0\n",
       "1  650 5590 753942 12 189 243 1 2039 47 257 682 1...       NaN\n",
       "2  34 23207 1523 4 57193 15 10777 14353 4 157019 ...       NaN\n",
       "3  418 0 1858 101 0 1322 1 5590 18 860 729 14 92 ...       NaN\n",
       "4  650 5590 1523 8 1136 15 11301 575 1156 1 2746 ...       NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a asociarle a cada oración el ID del artículo al cual pertenece.\n",
    "\n",
    "Es importante recordar que el orden de las oraciones está dado por los índices del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_ID_list = doc_0['art_ID'].tolist()\n",
    "art_ID = 0\n",
    "for idx, elem in enumerate(art_ID_list):\n",
    "    if not np.isnan(elem):\n",
    "        art_ID = elem\n",
    "    else:\n",
    "        art_ID_list[idx] = art_ID\n",
    "doc_0['art_ID'] = art_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos ahora las filas con NaN que contenian los ID de los artículos inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0 = doc_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento contiene 128395 oraciones.\n",
      "El documento contiene 1814 artículos\n"
     ]
    }
   ],
   "source": [
    "print('El documento contiene {} oraciones.'.format(doc_0.shape[0]))\n",
    "print('El documento contiene {} artículos'.format(len(doc_0['art_ID'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos que cada sentencia sea una lista de palabras codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0['sentence'] = doc_0['sentence'].map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...</td>\n",
       "      <td>431388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence    art_ID\n",
       "1  [650, 5590, 753942, 12, 189, 243, 1, 2039, 47,...  431388.0\n",
       "2  [34, 23207, 1523, 4, 57193, 15, 10777, 14353, ...  431388.0\n",
       "3  [418, 0, 1858, 101, 0, 1322, 1, 5590, 18, 860,...  431388.0\n",
       "4  [650, 5590, 1523, 8, 1136, 15, 11301, 575, 115...  431388.0\n",
       "5  [152, 642, 16, 8143, 23122, 20, 0, 662955, 16,...  431388.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con un artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>art_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>[63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>[3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>[24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>[152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>[64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  art_ID\n",
       "2756  [63903, 24730, 9, 7, 3035, 4104, 7584, 1, 355,...  1000.0\n",
       "2757  [3654, 16, 2502, 39413, 1, 24730, 9, 44, 3, 99...  1000.0\n",
       "2758  [24730, 35, 49, 3521, 15, 575, 1, 15, 2440, 1,...  1000.0\n",
       "2759  [152, 112, 8, 2037, 20, 52, 54, 3035, 17572, 3...  1000.0\n",
       "2760  [64, 62, 5787, 1132, 15, 0, 144, 24730, 1312, ...  1000.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = doc_0[doc_0.art_ID == 1000]\n",
    "article.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruimos la primera oración del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_decoder(sentence, word_mapping):\n",
    "    dec_sentence = []\n",
    "    for idx in sentence:\n",
    "        mapped_w = word_mapping.loc[np.int(idx), 'word']\n",
    "        dec_sentence.append(mapped_w)\n",
    "\n",
    "    return dec_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = article.loc[2756, 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hercule Poirot is a fictional Belgian detective , created by Agatha Christie .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_sentence = sentence_decoder(sentence, word_mapping)\n",
    "' '.join(dec_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings utilizando el modelo pre-entrenado word2vec de Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la librería Gensim https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos Google's pre-trained Word2Vec model.\n",
    "\n",
    "Utilizando KeyedVectors para cargar el modelo tiene la desventaja de que no se puede seguir entrenando. Pero es más eficiente que utilizar gensim.models.Word2Vec\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demora: 14.532685995101929\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# model = KeyedVectors.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# model.save('./models/word2vecGoogle.model')\n",
    "model = KeyedVectors.load('./models/word2vecGoogle.model')\n",
    "end = time.time()\n",
    "print('demora: {}'.format(end-start))\n",
    "# model = Word2Vec.load_word2vec_format('./models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de word embeddings: 3000000\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de word embeddings: {}'.format(len(model.vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidad de los vectores: 300\n"
     ]
    }
   ],
   "source": [
    "print('Dimensionalidad de los vectores: {}'.format(model.vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploremos distintas combinaciones de vectores de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación\n",
    "\n",
    "Este método consiste en concatenar los vectores de palabras que rodean una palabra objetivo en un vector más grande, que tiene un tamaño igual a las dimensiones agregadas de todos las proyecciones (embeddings) individuales. (DUDA: tamaño = $2 W D$)?\n",
    "\n",
    "- $w_{ij}$ = peso asociado con la i-ésima dimensión del vector de la j-ésima palabra en la oración. NOTA: con los vectores de palabras de una oración se forma una matriz $w^{\\space D\\space x\\space L}$ donde $L$ es la cantidad de palabras de esa oración.\n",
    "- $D$ = dimensionalidad de los word vectors originales. Por ejemplo, al usar el modelo word2vec de Google sabemos que D = 300.\n",
    "- $W$ = tamaño de ventana que se define como el número de palabras en un solo lado.\n",
    "\n",
    "Nos interesa representar el contexto de la I-ésima palabra de la oración. \n",
    "\n",
    "La i-ésima dimensión del vector de concatenación, que tiene un tamaño de $2 W D$, se calcula de la siguiente manera:\n",
    "\n",
    "$$ e_{i} =\\begin{cases} \n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & \\left\\lfloor{\\frac{i}{D}}\\right\\rfloor < W \\\\\n",
    "      w_{i\\space mod \\space D,\\space\\space I \\space - \\space W \\space + \\space 1\\space  +\\space\\left\\lfloor{\\frac{i}{D}}\\right\\rfloor} & c.c.\n",
    "   \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUDA: Cómo manejar caso de las palabras que están al comienzo (donde $W$ > #palabras a la izquierda) y al final (donde $W$ > #palabras a la derecha)?\n",
    "\n",
    "Utilizamos padding? En tal caso, de que manera? \n",
    "\n",
    "- Replicar las palabras que si se pudieron agregar al vector de contexto es una opción viable? \n",
    "- Hacer padding con 0's (tantos como el tamaño de la ventana)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promedio\n",
    "\n",
    "Como su nombre indica, se calcula el centroide de los embeddings de todas las palabras circundantes. La fórmula divide cada dimensión en $2W$ ya que el número de palabras del contexto es dos veces el tamaño de la ventana:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} \\frac{w_{ij}}{2W}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUDA: nuevamente como manejar caso de las palabras que están al comienzo ($W$ > #palabras a la izquierda) y al final ($W$ > #palabras a la derecha)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento fraccional\n",
    "\n",
    "Una tercera estrategia para construir un vector de carácteristicas en base a los embeddings de palabras contextuales está inspirada en la forma en que Word2vec combina las palabras en el contexto. Aquí, se supone que la importancia de una palabra para nuestra representación es inversamente proporcional a su distancia respecto a la palabra objetivo.\n",
    "\n",
    "Por lo tanto, las palabras contextuales se ponderan en función de su distancia de la palabra objetivo:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} *\\frac{W - \\lvert I-j\\rvert}{W}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decaimiento exponencial\n",
    "\n",
    "Funciona de manera similar al decaimiento fraccional, que le da más importancia al contexto cercano, pero en este caso la ponderación se realiza exponencialmente:\n",
    "\n",
    "$$\\sum_{\\substack{j\\space=\\space I-W \\\\ j\\space\\neq\\space I}}^{I + W} w_{ij} * (1 - \\alpha)^{\\lvert \\space I\\space-\\space j\\space\\rvert\\space-\\space1}$$\n",
    "\n",
    "donde $\\alpha = 1 - 0.1^{(W-1)^{-1}}$ es el parámetro de decaimiento. Elegimos el parámetro de tal manera que las palabras inmediatas que rodean a la palabra objetivo contribuyen 10 veces más que las últimas palabras en ambos lados de la ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
